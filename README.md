#Extending Minimum Prediction Deviation as a Defense Against Adversarial Attacks

In this project we extend the previous experiments conducted on MPD. The Minimum Prediction Deviation (MPD) is an uncertainty metric that can be used to detect adversarial examples. Our experiments demonstrate that MPD is domain and dataset-independent, detecting 93\% of adversarial samples across all datasets with an average false positive of only 2\%. Further, the high false positive rate, while appearing to be concerning, is, in fact, quite reasonable. This is due to the uncertainty attribute; we demonstrate that the samples falsely identified as adversarial have a high uncertainty which correlates to poor performance by the machine learning models. Simply put - it's a good thing to quarantine these samples as the machine learning model is likely to misclassify them regardless of being adversarial or not.
We demonstrate that MPD generalizes to multiclass classification problems and defends against FIGA (gradient-free) and PGD (gradient-based) attacks.

The code files are as described as below: 
1. full_binary_pgd.ipynb : This experimental file consists of the experiments run on an homogenous (MNIST) dataset. We have evaluated performance of our detection mechanism MPD using adversarial samples generated by an gradient-based attack called PGD. This experiment has machine learning models which were trained only on binary class classification. 
2. mpd_multifull.ipynb : This experimental file consists of the experiments run on an homogenous (MNIST) dataset. We have evaluated performance of our detection mechanism MPD using adversarial samples generated by an gradient-based attack called PGD. This experiment has machine learning models which were trained  on multi class classification.
3. /src folder consists of files which are generated between the experimental steps as described below:
--> there are 2 files called binary_MPD.py and multi_MPD.py which contains the code how MPD works respectively according to their dataset classification. It takes samples from testbed dataset as inputs and produces MPD scores which are also called as uncertainity scores of every sample and store them in the form of an array.
--> binary_model.joblib is a file with an machine learning model which is trained on binary class data. These are used to predict and evaluate.
--> dumpmodel.joblib is a file with an machine learning model which is trained on multi class data. These are used to predict and evaluate.
--> binary_mpd_dtc.joblib and new_mpd_dtc.joblib files are decision tree classifier models which are trained on their respective binary and multiclass datasets. 
--> training_5k_advsamples.joblib and testing_5k_advsamples.joblib are files which contain adversarial succesful samples which were an output generated from our adversarial attack called PGD. training_5k represents 5k samples taken from training data and testing_5k represents 5k samples taken from testing data. These samples are taken to evaluate our defense mechanism MPD and get performance metrics. 
